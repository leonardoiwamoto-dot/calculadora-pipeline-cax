import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import numpy as np
import gspread
from google.oauth2.service_account import Credentials

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Calculadora Pipeline CAX",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
    }
    
    .stage-sal { border-left-color: #3b82f6; }
    .stage-sql { border-left-color: #f59e0b; }
    .stage-opp { border-left-color: #ef4444; }
    .stage-bc { border-left-color: #10b981; }
    .stage-onb { border-left-color: #8b5cf6; }
</style>
""", unsafe_allow_html=True)

# FunÃ§Ã£o para conectar com Google Sheets
@st.cache_data(ttl=300)  # Cache por 5 minutos
def load_data():
    """Carrega dados do Google Sheets"""
    try:
        # ConfiguraÃ§Ã£o da conexÃ£o
        SPREADSHEET_ID = "1L0nO-rchxshEufLANyH3aEz6hFulvpq1OMPUzTw76LM"
        SHEET_NAME = "Pipeline"
        
        # Criar URL para CSV do Google Sheets
        csv_url = f"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}"
        
        # Carregar dados
        df = pd.read_csv(csv_url)
        
        # Limpar e processar dados
        df = df.dropna(subset=['id'])  # Remove linhas vazias
        df['data_entrada'] = pd.to_datetime(df['data_entrada'], errors='coerce')
        df['data_prevista_onboarding'] = pd.to_datetime(df['data_prevista_onboarding'], errors='coerce')
        
        return df
        
    except Exception as e:
        st.error(f"Erro ao carregar dados: {str(e)}")
        return pd.DataFrame()

# FunÃ§Ã£o para calcular mÃ©tricas do pipeline
def calculate_metrics(df):
    """Calcula mÃ©tricas do pipeline"""
    if df.empty:
        return {}
    
    today = datetime.now().date()
    
    # Contagem por etapa
    stage_counts = df['etapa'].value_counts().to_dict()
    
    # Deals para hoje
    deals_hoje = 0
    if 'data_prevista_onboarding' in df.columns:
        deals_hoje = len(df[df['data_prevista_onboarding'].dt.date == today])
    
    # Calcular dias na etapa (sÃ³ valores positivos)
    df['dias_na_etapa'] = (datetime.now() - df['data_entrada']).dt.days
    df['dias_na_etapa'] = df['dias_na_etapa'].clip(lower=0)  # Remover valores negativos
    
    # Deals atrasados (mais de 7 dias na etapa)
    deals_atrasados = len(df[df['dias_na_etapa'] > 7])
    
    return {
        'total_deals': len(df),
        'stage_counts': stage_counts,
        'deals_hoje': deals_hoje,
        'deals_atrasados': deals_atrasados,
        'dias_na_etapa': df['dias_na_etapa']
    }

# FunÃ§Ã£o para criar grÃ¡fico do funil
def create_funnel_chart(stage_counts):
    """Cria grÃ¡fico de funil das etapas"""
    stages = ['SAL', 'SQL', 'OPP', 'BC', 'ONB_AGEND']
    colors = ['#3b82f6', '#f59e0b', '#ef4444', '#10b981', '#8b5cf6']
    
    values = [stage_counts.get(stage, 0) for stage in stages]
    
    fig = go.Figure(go.Funnel(
        y=stages,
        x=values,
        textinfo="value+percent initial",
        marker={
            'color': colors,
            'line': {'width': 2, 'color': 'white'}
        }
    ))
    
    fig.update_layout(
        title="ðŸŽ¯ Funil de Vendas por Etapa",
        height=400,
        showlegend=False
    )
    
    return fig

# FunÃ§Ã£o para criar grÃ¡fico de timeline
def create_timeline_chart(df):
    """Cria grÃ¡fico de timeline dos deals"""
    if df.empty:
        return None
    
    # Garantir que dias_na_etapa seja positivo
    df_clean = df.copy()
    df_clean['dias_na_etapa'] = df_clean['dias_na_etapa'].clip(lower=1)  # MÃ­nimo 1 dia
    
    fig = px.scatter(
        df_clean, 
        x='data_entrada', 
        y='etapa',
        color='bdr',
        size='dias_na_etapa',
        hover_data=['dealname', 'dias_na_etapa'],
        title="ðŸ“… Timeline dos Deals por Etapa"
    )
    
    fig.update_layout(height=400)
    return fig

# FunÃ§Ãµes da Calculadora Pipeline
def get_business_days(start_date, num_days):
    """Retorna data apÃ³s N dias Ãºteis"""
    current = start_date
    days_added = 0
    
    while days_added < num_days:
        current += timedelta(days=1)
        if current.weekday() < 5:  # Segunda a sexta
            days_added += 1
    
    return current

def get_next_business_days(num_days=15):
    """Retorna prÃ³ximos N dias Ãºteis"""
    business_days = []
    current = datetime.now().date()
    
    while len(business_days) < num_days:
        current += timedelta(days=1)
        if current.weekday() < 5:
            business_days.append(current)
    
    return business_days

def calculate_pipeline_forecast(df, config):
    """Calcula previsÃ£o do pipeline para prÃ³ximos dias"""
    if df.empty:
        return []
    
    business_days = get_next_business_days(15)
    results = []
    
    for target_date in business_days:
        daily_result = {
            'date': pd.Timestamp(target_date),
            'SAL': 0, 'SQL': 0, 'OPP': 0, 'BC': 0, 'ONB': 0
        }
        
        for _, deal in df.iterrows():
            entry_date = deal['data_entrada'].date() if pd.notna(deal['data_entrada']) else datetime.now().date()
            current_stage = deal['etapa']
            
            # Calcular quando cada deal deve converter em cada etapa
            if current_stage == 'SAL':
                sql_date = get_business_days(entry_date, config['SAL']['days'])
                opp_date = get_business_days(sql_date, config['SQL']['days']) 
                bc_date = get_business_days(opp_date, config['OPP']['days'])
                onb_date = get_business_days(bc_date, config['BC']['days'])
                
                if target_date <= sql_date:
                    daily_result['SAL'] += 1
                elif target_date <= opp_date:
                    daily_result['SQL'] += config['SAL']['cvr'] / 100
                elif target_date <= bc_date:
                    daily_result['OPP'] += (config['SAL']['cvr'] / 100) * (config['SQL']['cvr'] / 100)
                elif target_date <= onb_date:
                    daily_result['BC'] += (config['SAL']['cvr'] / 100) * (config['SQL']['cvr'] / 100) * (config['OPP']['cvr'] / 100)
                else:
                    daily_result['ONB'] += (config['SAL']['cvr'] / 100) * (config['SQL']['cvr'] / 100) * (config['OPP']['cvr'] / 100) * (config['BC']['cvr'] / 100)
            
            elif current_stage == 'SQL':
                opp_date = get_business_days(entry_date, config['SQL']['days'])
                bc_date = get_business_days(opp_date, config['OPP']['days'])
                onb_date = get_business_days(bc_date, config['BC']['days'])
                
                if target_date <= opp_date:
                    daily_result['SQL'] += 1
                elif target_date <= bc_date:
                    daily_result['OPP'] += config['SQL']['cvr'] / 100
                elif target_date <= onb_date:
                    daily_result['BC'] += (config['SQL']['cvr'] / 100) * (config['OPP']['cvr'] / 100)
                else:
                    daily_result['ONB'] += (config['SQL']['cvr'] / 100) * (config['OPP']['cvr'] / 100) * (config['BC']['cvr'] / 100)
            
            elif current_stage == 'OPP':
                bc_date = get_business_days(entry_date, config['OPP']['days'])
                onb_date = get_business_days(bc_date, config['BC']['days'])
                
                if target_date <= bc_date:
                    daily_result['OPP'] += 1
                elif target_date <= onb_date:
                    daily_result['BC'] += config['OPP']['cvr'] / 100
                else:
                    daily_result['ONB'] += (config['OPP']['cvr'] / 100) * (config['BC']['cvr'] / 100)
            
            elif current_stage == 'BC':
                onb_date = get_business_days(entry_date, config['BC']['days'])
                
                if target_date <= onb_date:
                    daily_result['BC'] += 1
                else:
                    daily_result['ONB'] += config['BC']['cvr'] / 100
            
            elif current_stage == 'ONB_AGEND':
                # Se tem data prevista, usar ela, senÃ£o usar data entrada + lead time
                if pd.notna(deal['data_prevista_onboarding']):
                    onb_date = deal['data_prevista_onboarding'].date()
                else:
                    onb_date = get_business_days(entry_date, 2)  # Default 2 dias
                
                if target_date >= onb_date:
                    daily_result['ONB'] += 1
        
        # Arredondar valores
        for key in ['SAL', 'SQL', 'OPP', 'BC', 'ONB']:
            daily_result[key] = round(daily_result[key], 1)
        
        results.append(daily_result)
    
    return results

def create_pipeline_evolution_chart(df_pipeline):
    """Cria grÃ¡fico de evoluÃ§Ã£o do pipeline"""
    fig = go.Figure()
    
    colors = {
        'SAL': '#3b82f6',
        'SQL': '#f59e0b', 
        'OPP': '#ef4444',
        'BC': '#10b981',
        'ONB': '#8b5cf6'
    }
    
    for stage in ['SAL', 'SQL', 'OPP', 'BC', 'ONB']:
        fig.add_trace(go.Scatter(
            x=df_pipeline['date'],
            y=df_pipeline[stage],
            mode='lines+markers',
            name=stage,
            line=dict(color=colors[stage], width=3),
            marker=dict(size=6)
        ))
    
    fig.update_layout(
        title="ðŸ“ˆ EvoluÃ§Ã£o do Pipeline - PrÃ³ximos 15 dias",
        xaxis_title="Data",
        yaxis_title="NÃºmero de Deals",
        height=500,
        hovermode='x unified'
    )
    
    return fig

def get_next_wednesday_deals(df_pipeline):
    """Retorna deals para prÃ³xima quarta-feira"""
    today = datetime.now().date()
    
    # Encontrar prÃ³xima quarta-feira
    days_until_wednesday = (2 - today.weekday()) % 7
    if days_until_wednesday == 0:  # Se hoje Ã© quarta
        days_until_wednesday = 7
    
    next_wednesday = today + timedelta(days=days_until_wednesday)
    
    # Encontrar na tabela
    wednesday_row = df_pipeline[df_pipeline['date'].dt.date == next_wednesday]
    
    if not wednesday_row.empty:
        return wednesday_row.iloc[0]['ONB']
    
    return 0

def calculate_scenario_impact(new_sal, new_sql, new_opp, config):
    """Calcula impacto de um cenÃ¡rio de novos deals"""
    
    # Calcular conversÃµes em cascata
    sal_to_onb = new_sal * (config['SAL']['cvr']/100) * (config['SQL']['cvr']/100) * (config['OPP']['cvr']/100) * (config['BC']['cvr']/100)
    sql_to_onb = new_sql * (config['SQL']['cvr']/100) * (config['OPP']['cvr']/100) * (config['BC']['cvr']/100)
    opp_to_onb = new_opp * (config['OPP']['cvr']/100) * (config['BC']['cvr']/100)
    
    total_onbs = sal_to_onb + sql_to_onb + opp_to_onb
    
    # Calcular quando primeira conversÃ£o acontece
    min_days = float('inf')
    if new_sal > 0:
        sal_days = config['SAL']['days'] + config['SQL']['days'] + config['OPP']['days'] + config['BC']['days']
        min_days = min(min_days, sal_days)
    if new_sql > 0:
        sql_days = config['SQL']['days'] + config['OPP']['days'] + config['BC']['days']
        min_days = min(min_days, sql_days)
    if new_opp > 0:
        opp_days = config['OPP']['days'] + config['BC']['days']
        min_days = min(min_days, opp_days)
    
    first_conversion_days = min_days if min_days != float('inf') else 0
    
    # Estimativa de receita (R$ 50.000 por ONB)
    estimated_revenue = total_onbs * 50000
    
    return {
        'additional_onbs': total_onbs,
        'first_conversion_days': first_conversion_days,
        'estimated_revenue': estimated_revenue
    }

# INTERFACE PRINCIPAL
def main():
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ðŸ“Š Calculadora Pipeline CAX</h1>
        <p>Dashboard em tempo real conectado com Google Sheets</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Carregar dados
    with st.spinner("ðŸ”„ Carregando dados da planilha..."):
        df = load_data()
    
    if df.empty:
        st.error("âŒ NÃ£o foi possÃ­vel carregar os dados. Verifique a planilha.")
        st.info("ðŸ’¡ Certifique-se que a planilha estÃ¡ com permissÃ£o 'Qualquer pessoa com o link pode visualizar'")
        return
    
    # Sidebar - Filtros
    st.sidebar.header("ðŸŽ¯ Filtros")
    
    # Filtro por BDR
    bdrs = ['Todos'] + sorted(df['bdr'].dropna().unique().tolist())
    selected_bdr = st.sidebar.selectbox("ðŸ‘¤ Selecionar BDR", bdrs)
    
    # Filtro por etapa
    etapas = ['Todas'] + sorted(df['etapa'].dropna().unique().tolist())
    selected_etapa = st.sidebar.selectbox("ðŸŽ¯ Selecionar Etapa", etapas)
    
    # Aplicar filtros
    filtered_df = df.copy()
    if selected_bdr != 'Todos':
        filtered_df = filtered_df[filtered_df['bdr'] == selected_bdr]
    if selected_etapa != 'Todas':
        filtered_df = filtered_df[filtered_df['etapa'] == selected_etapa]
    
    # Calcular mÃ©tricas
    metrics = calculate_metrics(filtered_df)
    
    # InformaÃ§Ãµes no sidebar
    st.sidebar.markdown("---")
    st.sidebar.metric("ðŸ“Š Total de Deals", metrics.get('total_deals', 0))
    st.sidebar.metric("ðŸ“… Para Hoje", metrics.get('deals_hoje', 0))
    st.sidebar.metric("âš ï¸ Atrasados", metrics.get('deals_atrasados', 0))
    
    # BotÃ£o de atualizar
    if st.sidebar.button("ðŸ”„ Atualizar Dados"):
        st.cache_data.clear()
        st.rerun()
    
    # Layout principal com tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ðŸ”® Calculadora Pipeline", "ðŸ“ˆ Dashboard", "ðŸ“‹ Lista de Deals", "âš ï¸ Deals Atrasados", "ðŸ“Š AnÃ¡lises"])
    
    # TAB 1: CALCULADORA PIPELINE (PRINCIPAL)
    with tab1:
        st.header("ðŸ”® Calculadora Pipeline de Vendas")
        
        # ConfiguraÃ§Ãµes do funil
        st.subheader("âš™ï¸ ConfiguraÃ§Ãµes do Funil")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Taxa de ConversÃ£o (%)**")
            sal_cvr = st.slider("SAL â†’ SQL", 0, 100, 80, key="sal_cvr")
            sql_cvr = st.slider("SQL â†’ OPP", 0, 100, 90, key="sql_cvr") 
            opp_cvr = st.slider("OPP â†’ BC", 0, 100, 75, key="opp_cvr")
            bc_cvr = st.slider("BC â†’ ONB", 0, 100, 67, key="bc_cvr")
        
        with col2:
            st.write("**Lead Time (dias Ãºteis)**")
            sal_days = st.number_input("SAL Lead Time", 0, 30, 2, key="sal_days")
            sql_days = st.number_input("SQL Lead Time", 0, 30, 0, key="sql_days")
            opp_days = st.number_input("OPP Lead Time", 0, 30, 2, key="opp_days")
            bc_days = st.number_input("BC Lead Time", 0, 30, 5, key="bc_days")
        
        # Calcular pipeline atual
        if not filtered_df.empty:
            pipeline_results = calculate_pipeline_forecast(filtered_df, {
                'SAL': {'cvr': sal_cvr, 'days': sal_days},
                'SQL': {'cvr': sql_cvr, 'days': sql_days}, 
                'OPP': {'cvr': opp_cvr, 'days': opp_days},
                'BC': {'cvr': bc_cvr, 'days': bc_days}
            })
            
            # Tabela de previsÃ£o
            st.subheader("ðŸ“… PrevisÃ£o Pipeline - PrÃ³ximos 15 dias Ãºteis")
            
            if pipeline_results:
                df_pipeline = pd.DataFrame(pipeline_results)
                df_pipeline['Data'] = df_pipeline['date'].dt.strftime('%d/%m')
                df_pipeline['Dia'] = df_pipeline['date'].dt.strftime('%a')
                
                # Destacar quartas-feiras
                def highlight_wednesday(row):
                    if row['date'].weekday() == 2:  # Quarta-feira
                        return ['background-color: #fff3cd'] * len(row)
                    return [''] * len(row)
                
                display_cols = ['Data', 'Dia', 'SAL', 'SQL', 'OPP', 'BC', 'ONB']
                styled_df = df_pipeline[display_cols].style.apply(highlight_wednesday, axis=1)
                
                st.dataframe(styled_df, use_container_width=True, height=400)
                
                # GrÃ¡fico de evoluÃ§Ã£o
                fig_evolution = create_pipeline_evolution_chart(df_pipeline)
                st.plotly_chart(fig_evolution, use_container_width=True)
                
                # MÃ©tricas de resumo
                col1, col2, col3, col4 = st.columns(4)
                
                total_onb_15_days = df_pipeline['ONB'].sum()
                deals_proxima_quarta = get_next_wednesday_deals(df_pipeline)
                
                with col1:
                    st.metric("ðŸŽ¯ ONBs prÃ³ximos 15 dias", f"{total_onb_15_days:.1f}")
                with col2:
                    st.metric("ðŸ“… ONBs prÃ³xima quarta", f"{deals_proxima_quarta:.1f}")
                with col3:
                    pipeline_atual = filtered_df.shape[0]
                    st.metric("ðŸ“Š Pipeline atual", pipeline_atual)
                with col4:
                    conversion_rate = (total_onb_15_days / pipeline_atual * 100) if pipeline_atual > 0 else 0
                    st.metric("ðŸ“ˆ Taxa conversÃ£o", f"{conversion_rate:.1f}%")
        
        # Teste de cenÃ¡rios
        st.subheader("ðŸŽ® Teste de CenÃ¡rios")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            scenario_sal = st.number_input("Novos SALs hoje", 0, 100, 5, key="scenario_sal")
        with col2:
            scenario_sql = st.number_input("Novos SQLs hoje", 0, 100, 2, key="scenario_sql") 
        with col3:
            scenario_opp = st.number_input("Novos OPPs hoje", 0, 100, 1, key="scenario_opp")
        
        if st.button("ðŸ”® Calcular CenÃ¡rio"):
            scenario_results = calculate_scenario_impact(
                scenario_sal, scenario_sql, scenario_opp,
                {
                    'SAL': {'cvr': sal_cvr, 'days': sal_days},
                    'SQL': {'cvr': sql_cvr, 'days': sql_days},
                    'OPP': {'cvr': opp_cvr, 'days': opp_days}, 
                    'BC': {'cvr': bc_cvr, 'days': bc_days}
                }
            )
            
            st.success(f"**Impacto do CenÃ¡rio:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ðŸŽ¯ ONBs adicionais", f"+{scenario_results['additional_onbs']:.1f}")
            with col2:
                st.metric("ðŸ“… Primeira conversÃ£o em", f"{scenario_results['first_conversion_days']} dias")
            with col3:
                st.metric("ðŸ’° Receita estimada", f"R$ {scenario_results['estimated_revenue']:,.0f}")
        
        else:
            st.info("ðŸ‘† Configure o cenÃ¡rio acima e clique em 'Calcular CenÃ¡rio'")
    
    with tab2:
        # MÃ©tricas principais
        col1, col2, col3, col4 = st.columns(4)
        
        stage_counts = metrics.get('stage_counts', {})
        
        with col1:
            st.metric("ðŸ”µ SAL", stage_counts.get('SAL', 0))
        with col2:
            st.metric("ðŸŸ¡ OPP", stage_counts.get('OPP', 0))
        with col3:
            st.metric("ðŸŸ¢ BC", stage_counts.get('BC', 0))
        with col4:
            st.metric("ðŸŸ£ ONB_AGEND", stage_counts.get('ONB_AGEND', 0))
        
        # GrÃ¡ficos
        col1, col2 = st.columns(2)
        
        with col1:
            # GrÃ¡fico de funil
            funnel_fig = create_funnel_chart(stage_counts)
            st.plotly_chart(funnel_fig, use_container_width=True)
        
        with col2:
            # GrÃ¡fico de distribuiÃ§Ã£o por BDR
            if not filtered_df.empty:
                bdr_counts = filtered_df['bdr'].value_counts()
                fig = px.pie(
                    values=bdr_counts.values, 
                    names=bdr_counts.index,
                    title="ðŸ‘¥ DistribuiÃ§Ã£o por BDR"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    # TAB 3: Lista de Deals
    with tab3:
        st.subheader("ðŸ“‹ Lista Completa de Deals")
        
        if not filtered_df.empty:
            # Adicionar coluna de dias na etapa
            display_df = filtered_df.copy()
            display_df['dias_na_etapa'] = (datetime.now() - display_df['data_entrada']).dt.days
            
            # Selecionar colunas para exibir
            columns_to_show = ['id', 'dealname', 'etapa', 'data_entrada', 'bdr', 'dias_na_etapa']
            display_df = display_df[columns_to_show]
            
            # Ordenar por data de entrada (mais recente primeiro)
            display_df = display_df.sort_values('data_entrada', ascending=False)
            
            # Exibir tabela
            st.dataframe(
                display_df,
                use_container_width=True,
                height=600
            )
            
            # Download
            csv = display_df.to_csv(index=False)
            st.download_button(
                "ðŸ“¥ Download CSV",
                csv,
                "pipeline_deals.csv",
                "text/csv"
            )
        else:
            st.info("Nenhum deal encontrado com os filtros selecionados.")
    
    # TAB 4: Deals Atrasados
    with tab4:
        st.subheader("âš ï¸ Deals Atrasados (7+ dias na etapa)")
        
        if not filtered_df.empty:
            # Filtrar deals atrasados
            dias_na_etapa = (datetime.now() - filtered_df['data_entrada']).dt.days
            atrasados_df = filtered_df[dias_na_etapa > 7].copy()
            atrasados_df['dias_na_etapa'] = dias_na_etapa[dias_na_etapa > 7]
            
            if not atrasados_df.empty:
                # Ordenar por dias na etapa (mais atrasado primeiro)
                atrasados_df = atrasados_df.sort_values('dias_na_etapa', ascending=False)
                
                # Adicionar cor baseada na urgÃªncia
                def get_urgency_color(dias):
                    if dias > 14:
                        return "ðŸ”´"
                    elif dias > 10:
                        return "ðŸŸ¡"
                    else:
                        return "ðŸŸ "
                
                atrasados_df['urgencia'] = atrasados_df['dias_na_etapa'].apply(get_urgency_color)
                
                # Selecionar colunas
                columns_to_show = ['urgencia', 'dealname', 'etapa', 'data_entrada', 'bdr', 'dias_na_etapa']
                display_df = atrasados_df[columns_to_show]
                
                st.dataframe(display_df, use_container_width=True, height=400)
                
                # MÃ©tricas de urgÃªncia
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ðŸ”´ CrÃ­ticos (14+ dias)", len(atrasados_df[atrasados_df['dias_na_etapa'] > 14]))
                with col2:
                    st.metric("ðŸŸ¡ AtenÃ§Ã£o (10-14 dias)", len(atrasados_df[(atrasados_df['dias_na_etapa'] > 10) & (atrasados_df['dias_na_etapa'] <= 14)]))
                with col3:
                    st.metric("ðŸŸ  Moderado (7-10 dias)", len(atrasados_df[(atrasados_df['dias_na_etapa'] > 7) & (atrasados_df['dias_na_etapa'] <= 10)]))
            else:
                st.success("ðŸŽ‰ Nenhum deal atrasado! Excelente trabalho!")
        else:
            st.info("Nenhum dado disponÃ­vel.")
    
    # TAB 5: AnÃ¡lises
    with tab5:
        st.subheader("ðŸ“Š AnÃ¡lises AvanÃ§adas")
        
        if not filtered_df.empty:
            # Timeline dos deals
            timeline_fig = create_timeline_chart(filtered_df)
            if timeline_fig:
                st.plotly_chart(timeline_fig, use_container_width=True)
            
            # EstatÃ­sticas por etapa
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ðŸ“ˆ Tempo MÃ©dio por Etapa")
                tempo_por_etapa = filtered_df.groupby('etapa')['dias_na_etapa'].agg(['mean', 'median', 'std']).round(1)
                st.dataframe(tempo_por_etapa)
            
            with col2:
                st.subheader("ðŸ‘¥ Performance por BDR")
                perf_bdr = filtered_df.groupby('bdr').agg({
                    'id': 'count',
                    'dias_na_etapa': 'mean'
                }).round(1)
                perf_bdr.columns = ['Total Deals', 'Tempo MÃ©dio']
                st.dataframe(perf_bdr)
        else:
            st.info("Selecione filtros para ver as anÃ¡lises.")
    
    # Footer
    st.markdown("---")
    st.markdown(f"ðŸ”„ **Ãšltima atualizaÃ§Ã£o:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    st.markdown("ðŸ“Š **Dados em tempo real** conectados com Google Sheets")

if __name__ == "__main__":
    main()
